
@misc{wang_instructuie_2023,
	title = {{InstructUIE}: {Multi}-task {Instruction} {Tuning} for {Unified} {Information} {Extraction}},
	shorttitle = {{InstructUIE}},
	url = {http://arxiv.org/abs/2304.08085},
	doi = {10.48550/arXiv.2304.08085},
	abstract = {Large language models have unlocked strong multi-task capabilities from reading instructive prompts. However, recent studies have shown that existing large models still have difficulty with information extraction tasks. For example, gpt-3.5-turbo achieved an F1 score of 18.22 on the Ontonotes dataset, which is significantly lower than the state-of-the-art performance. In this paper, we propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency. To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions. Experimental results demonstrate that our method achieves comparable performance to Bert in supervised settings and significantly outperforms the state-of-the-art and gpt3.5 in zero-shot settings.},
	urldate = {2023-04-23},
	publisher = {arXiv},
	author = {Wang, Xiao and Zhou, Weikang and Zu, Can and Xia, Han and Chen, Tianze and Zhang, Yuansen and Zheng, Rui and Ye, Junjie and Zhang, Qi and Gui, Tao and Kang, Jihua and Yang, Jingsheng and Li, Siyuan and Du, Chunsai},
	month = apr,
	year = {2023},
	note = {arXiv:2304.08085 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:E\:\\Books and Papers\\Zotero\\storage\\4KS9RWIJ\\2304.html:text/html;Wang et al_2023_InstructUIE.pdf:E\:\\Books and Papers\\Zotero\\storage\\KEDABGNI\\Wang et al_2023_InstructUIE.pdf:application/pdf},
}

@misc{liu_rexuie_2023,
	title = {{RexUIE}: {A} {Recursive} {Method} with {Explicit} {Schema} {Instructor} for {Universal} {Information} {Extraction}},
	shorttitle = {{RexUIE}},
	url = {http://arxiv.org/abs/2304.14770},
	abstract = {Universal Information Extraction (UIE) is an area of interest due to the challenges posed by varying targets, heterogeneous structures, and demand-specific schemas. However, previous works have only achieved limited success by unifying a few tasks, such as Named Entity Recognition (NER) and Relation Extraction (RE), which fall short of being authentic UIE models particularly when extracting other general schemas such as quadruples and quintuples. Additionally, these models used an implicit structural schema instructor, which could lead to incorrect links between types, hindering the model's generalization and performance in low-resource scenarios. In this paper, we redefine the authentic UIE with a formal formulation that encompasses almost all extraction schemas. To the best of our knowledge, we are the first to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which is a Recursive Method with Explicit Schema Instructor for UIE. To avoid interference between different types, we reset the position ids and attention mask matrices. RexUIE shows strong performance under both full-shot and few-shot settings and achieves State-of-the-Art results on the tasks of extracting complex schemas.},
	urldate = {2023-05-03},
	publisher = {arXiv},
	author = {Liu, Chengyuan and Zhao, Fubang and Kang, Yangyang and Zhang, Jingyuan and Zhou, Xiang and Sun, Changlong and Wu, Fei and Kuang, Kun},
	month = apr,
	year = {2023},
	note = {arXiv:2304.14770 [cs]
version: 1},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:E\:\\Books and Papers\\Zotero\\storage\\HBNVHK88\\2304.html:text/html;Liu et al_2023_RexUIE.pdf:E\:\\Books and Papers\\Zotero\\storage\\LE4PERJ4\\Liu et al_2023_RexUIE.pdf:application/pdf},
}

@misc{lu_uniex_2023,
	title = {{UniEX}: {An} {Effective} and {Efficient} {Framework} for {Unified} {Information} {Extraction} via a {Span}-extractive {Perspective}},
	shorttitle = {{UniEX}},
	url = {http://arxiv.org/abs/2305.10306},
	doi = {10.48550/arXiv.2305.10306},
	abstract = {We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on \$14\$ benchmarks IE datasets with the supervised setting. The state-of-the-art performance in low-resource scenarios also verifies the transferability and effectiveness of UniEX.},
	urldate = {2023-05-18},
	publisher = {arXiv},
	author = {Lu, Junyu and Yang, Ping and Gan, Ruyi and Wang, Junjie and Zhang, Yuxiang and Zhang, Jiaxing and Zhang, Pingjian},
	month = may,
	year = {2023},
	note = {arXiv:2305.10306 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:E\:\\Books and Papers\\Zotero\\storage\\PIJ763G8\\2305.html:text/html;Lu et al_2023_UniEX.pdf:E\:\\Books and Papers\\Zotero\\storage\\ESVNJ6YW\\Lu et al_2023_UniEX.pdf:application/pdf},
}
